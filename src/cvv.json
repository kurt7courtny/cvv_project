{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "VideoInput",
            "id": "VideoInput-opMrl",
            "name": "video_out",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "video_in",
            "id": "AudioExtractor-OocpO",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-VideoInput-opMrl{Å“dataTypeÅ“:Å“VideoInputÅ“,Å“idÅ“:Å“VideoInput-opMrlÅ“,Å“nameÅ“:Å“video_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-AudioExtractor-OocpO{Å“fieldNameÅ“:Å“video_inÅ“,Å“idÅ“:Å“AudioExtractor-OocpOÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "selected": false,
        "source": "VideoInput-opMrl",
        "sourceHandle": "{Å“dataTypeÅ“:Å“VideoInputÅ“,Å“idÅ“:Å“VideoInput-opMrlÅ“,Å“nameÅ“:Å“video_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
        "target": "AudioExtractor-OocpO",
        "targetHandle": "{Å“fieldNameÅ“:Å“video_inÅ“,Å“idÅ“:Å“AudioExtractor-OocpOÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "AudioExtractor",
            "id": "AudioExtractor-OocpO",
            "name": "audio_out",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "audio_in",
            "id": "SpeakerDiarization-z5MtQ",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-AudioExtractor-OocpO{Å“dataTypeÅ“:Å“AudioExtractorÅ“,Å“idÅ“:Å“AudioExtractor-OocpOÅ“,Å“nameÅ“:Å“audio_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-SpeakerDiarization-z5MtQ{Å“fieldNameÅ“:Å“audio_inÅ“,Å“idÅ“:Å“SpeakerDiarization-z5MtQÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "selected": false,
        "source": "AudioExtractor-OocpO",
        "sourceHandle": "{Å“dataTypeÅ“:Å“AudioExtractorÅ“,Å“idÅ“:Å“AudioExtractor-OocpOÅ“,Å“nameÅ“:Å“audio_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
        "target": "SpeakerDiarization-z5MtQ",
        "targetHandle": "{Å“fieldNameÅ“:Å“audio_inÅ“,Å“idÅ“:Å“SpeakerDiarization-z5MtQÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SpeakerDiarization",
            "id": "SpeakerDiarization-z5MtQ",
            "name": "segments_out",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "seg_in",
            "id": "SegmentASR-YElxR",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-SpeakerDiarization-z5MtQ{Å“dataTypeÅ“:Å“SpeakerDiarizationÅ“,Å“idÅ“:Å“SpeakerDiarization-z5MtQÅ“,Å“nameÅ“:Å“segments_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-SegmentASR-YElxR{Å“fieldNameÅ“:Å“seg_inÅ“,Å“idÅ“:Å“SegmentASR-YElxRÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "selected": false,
        "source": "SpeakerDiarization-z5MtQ",
        "sourceHandle": "{Å“dataTypeÅ“:Å“SpeakerDiarizationÅ“,Å“idÅ“:Å“SpeakerDiarization-z5MtQÅ“,Å“nameÅ“:Å“segments_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
        "target": "SegmentASR-YElxR",
        "targetHandle": "{Å“fieldNameÅ“:Å“seg_inÅ“,Å“idÅ“:Å“SegmentASR-YElxRÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SegmentASR",
            "id": "SegmentASR-YElxR",
            "name": "asr_out",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "asr_in",
            "id": "SpeakerAttribute-oyrcV",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-SegmentASR-YElxR{Å“dataTypeÅ“:Å“SegmentASRÅ“,Å“idÅ“:Å“SegmentASR-YElxRÅ“,Å“nameÅ“:Å“asr_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-SpeakerAttribute-oyrcV{Å“fieldNameÅ“:Å“asr_inÅ“,Å“idÅ“:Å“SpeakerAttribute-oyrcVÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "selected": false,
        "source": "SegmentASR-YElxR",
        "sourceHandle": "{Å“dataTypeÅ“:Å“SegmentASRÅ“,Å“idÅ“:Å“SegmentASR-YElxRÅ“,Å“nameÅ“:Å“asr_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
        "target": "SpeakerAttribute-oyrcV",
        "targetHandle": "{Å“fieldNameÅ“:Å“asr_inÅ“,Å“idÅ“:Å“SpeakerAttribute-oyrcVÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "SpeakerAttribute",
            "id": "SpeakerAttribute-oyrcV",
            "name": "attr_out",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "attr_in",
            "id": "DialogueTable-anbT7",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-SpeakerAttribute-oyrcV{Å“dataTypeÅ“:Å“SpeakerAttributeÅ“,Å“idÅ“:Å“SpeakerAttribute-oyrcVÅ“,Å“nameÅ“:Å“attr_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-DialogueTable-anbT7{Å“fieldNameÅ“:Å“attr_inÅ“,Å“idÅ“:Å“DialogueTable-anbT7Å“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "selected": false,
        "source": "SpeakerAttribute-oyrcV",
        "sourceHandle": "{Å“dataTypeÅ“:Å“SpeakerAttributeÅ“,Å“idÅ“:Å“SpeakerAttribute-oyrcVÅ“,Å“nameÅ“:Å“attr_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
        "target": "DialogueTable-anbT7",
        "targetHandle": "{Å“fieldNameÅ“:Å“attr_inÅ“,Å“idÅ“:Å“DialogueTable-anbT7Å“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DialogueTable",
            "id": "DialogueTable-anbT7",
            "name": "df_out",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df_in",
            "id": "PoeTranslator-K0YVQ",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-DialogueTable-anbT7{Å“dataTypeÅ“:Å“DialogueTableÅ“,Å“idÅ“:Å“DialogueTable-anbT7Å“,Å“nameÅ“:Å“df_outÅ“,Å“output_typesÅ“:[Å“DataFrameÅ“]}-PoeTranslator-K0YVQ{Å“fieldNameÅ“:Å“df_inÅ“,Å“idÅ“:Å“PoeTranslator-K0YVQÅ“,Å“inputTypesÅ“:[Å“DataFrameÅ“],Å“typeÅ“:Å“otherÅ“}",
        "selected": false,
        "source": "DialogueTable-anbT7",
        "sourceHandle": "{Å“dataTypeÅ“:Å“DialogueTableÅ“,Å“idÅ“:Å“DialogueTable-anbT7Å“,Å“nameÅ“:Å“df_outÅ“,Å“output_typesÅ“:[Å“DataFrameÅ“]}",
        "target": "PoeTranslator-K0YVQ",
        "targetHandle": "{Å“fieldNameÅ“:Å“df_inÅ“,Å“idÅ“:Å“PoeTranslator-K0YVQÅ“,Å“inputTypesÅ“:[Å“DataFrameÅ“],Å“typeÅ“:Å“otherÅ“}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ZeroShotTTS",
            "id": "ZeroShotTTS-XOsVg",
            "name": "tts_out",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "tts_in",
            "id": "AudioMerger-SjPk8",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ZeroShotTTS-XOsVg{Å“dataTypeÅ“:Å“ZeroShotTTSÅ“,Å“idÅ“:Å“ZeroShotTTS-XOsVgÅ“,Å“nameÅ“:Å“tts_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-AudioMerger-SjPk8{Å“fieldNameÅ“:Å“tts_inÅ“,Å“idÅ“:Å“AudioMerger-SjPk8Å“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "selected": false,
        "source": "ZeroShotTTS-XOsVg",
        "sourceHandle": "{Å“dataTypeÅ“:Å“ZeroShotTTSÅ“,Å“idÅ“:Å“ZeroShotTTS-XOsVgÅ“,Å“nameÅ“:Å“tts_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
        "target": "AudioMerger-SjPk8",
        "targetHandle": "{Å“fieldNameÅ“:Å“tts_inÅ“,Å“idÅ“:Å“AudioMerger-SjPk8Å“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "AudioMerger",
            "id": "AudioMerger-SjPk8",
            "name": "audio_out",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "audio_in",
            "id": "VideoComposer-QNxnb",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-AudioMerger-SjPk8{Å“dataTypeÅ“:Å“AudioMergerÅ“,Å“idÅ“:Å“AudioMerger-SjPk8Å“,Å“nameÅ“:Å“audio_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-VideoComposer-QNxnb{Å“fieldNameÅ“:Å“audio_inÅ“,Å“idÅ“:Å“VideoComposer-QNxnbÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "selected": false,
        "source": "AudioMerger-SjPk8",
        "sourceHandle": "{Å“dataTypeÅ“:Å“AudioMergerÅ“,Å“idÅ“:Å“AudioMerger-SjPk8Å“,Å“nameÅ“:Å“audio_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
        "target": "VideoComposer-QNxnb",
        "targetHandle": "{Å“fieldNameÅ“:Å“audio_inÅ“,Å“idÅ“:Å“VideoComposer-QNxnbÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "VideoInput",
            "id": "VideoInput-opMrl",
            "name": "video_out",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "video_in",
            "id": "VideoComposer-QNxnb",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-VideoInput-opMrl{Å“dataTypeÅ“:Å“VideoInputÅ“,Å“idÅ“:Å“VideoInput-opMrlÅ“,Å“nameÅ“:Å“video_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-VideoComposer-QNxnb{Å“fieldNameÅ“:Å“video_inÅ“,Å“idÅ“:Å“VideoComposer-QNxnbÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}",
        "selected": false,
        "source": "VideoInput-opMrl",
        "sourceHandle": "{Å“dataTypeÅ“:Å“VideoInputÅ“,Å“idÅ“:Å“VideoInput-opMrlÅ“,Å“nameÅ“:Å“video_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
        "target": "VideoComposer-QNxnb",
        "targetHandle": "{Å“fieldNameÅ“:Å“video_inÅ“,Å“idÅ“:Å“VideoComposer-QNxnbÅ“,Å“inputTypesÅ“:[Å“DataÅ“],Å“typeÅ“:Å“otherÅ“}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "PoeTranslator",
            "id": "PoeTranslator-K0YVQ",
            "name": "df_out",
            "output_types": [
              "DataFrame"
            ]
          },
          "targetHandle": {
            "fieldName": "df_in",
            "id": "ZeroShotTTS-XOsVg",
            "inputTypes": [
              "DataFrame"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-PoeTranslator-K0YVQ{Å“dataTypeÅ“:Å“PoeTranslatorÅ“,Å“idÅ“:Å“PoeTranslator-K0YVQÅ“,Å“nameÅ“:Å“df_outÅ“,Å“output_typesÅ“:[Å“DataFrameÅ“]}-ZeroShotTTS-XOsVg{Å“fieldNameÅ“:Å“df_inÅ“,Å“idÅ“:Å“ZeroShotTTS-XOsVgÅ“,Å“inputTypesÅ“:[Å“DataFrameÅ“],Å“typeÅ“:Å“otherÅ“}",
        "selected": false,
        "source": "PoeTranslator-K0YVQ",
        "sourceHandle": "{Å“dataTypeÅ“:Å“PoeTranslatorÅ“,Å“idÅ“:Å“PoeTranslator-K0YVQÅ“,Å“nameÅ“:Å“df_outÅ“,Å“output_typesÅ“:[Å“DataFrameÅ“]}",
        "target": "ZeroShotTTS-XOsVg",
        "targetHandle": "{Å“fieldNameÅ“:Å“df_inÅ“,Å“idÅ“:Å“ZeroShotTTS-XOsVgÅ“,Å“inputTypesÅ“:[Å“DataFrameÅ“],Å“typeÅ“:Å“otherÅ“}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "VideoComposer",
            "id": "VideoComposer-QNxnb",
            "name": "video_out",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-1nIGb",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-VideoComposer-QNxnb{Å“dataTypeÅ“:Å“VideoComposerÅ“,Å“idÅ“:Å“VideoComposer-QNxnbÅ“,Å“nameÅ“:Å“video_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}-ChatOutput-1nIGb{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ChatOutput-1nIGbÅ“,Å“inputTypesÅ“:[Å“DataÅ“,Å“DataFrameÅ“,Å“MessageÅ“],Å“typeÅ“:Å“otherÅ“}",
        "selected": false,
        "source": "VideoComposer-QNxnb",
        "sourceHandle": "{Å“dataTypeÅ“:Å“VideoComposerÅ“,Å“idÅ“:Å“VideoComposer-QNxnbÅ“,Å“nameÅ“:Å“video_outÅ“,Å“output_typesÅ“:[Å“DataÅ“]}",
        "target": "ChatOutput-1nIGb",
        "targetHandle": "{Å“fieldNameÅ“:Å“input_valueÅ“,Å“idÅ“:Å“ChatOutput-1nIGbÅ“,Å“inputTypesÅ“:[Å“DataÅ“,Å“DataFrameÅ“,Å“MessageÅ“],Å“typeÅ“:Å“otherÅ“}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "VideoInput-opMrl",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "é€‰æ‹©æœ¬åœ°è§†é¢‘æ–‡ä»¶",
            "display_name": "1ï¸âƒ£ è§†é¢‘è¾“å…¥",
            "documentation": "",
            "edited": false,
            "field_order": [
              "video_path"
            ],
            "frozen": false,
            "icon": "upload",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "è§†é¢‘è·¯å¾„",
                "hidden": false,
                "method": "send",
                "name": "video_out",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# media_pipeline/1_video_input.py\nfrom pathlib import Path\n\nfrom langflow.custom import Component\nfrom langflow.io import FileInput, Output\nfrom langflow.schema import Data\n\n\nclass VideoInput(Component):\n    display_name = \"1ï¸âƒ£ è§†é¢‘è¾“å…¥\"\n    description = \"é€‰æ‹©æœ¬åœ°è§†é¢‘æ–‡ä»¶\"\n    icon = \"upload\"\n    name = \"VideoInput\"\n\n    inputs = [\n        FileInput(name=\"video_path\", display_name=\"è§†é¢‘æ–‡ä»¶\", file_types=[\"mp4\", \"mov\", \"mkv\"], required=True),\n    ]\n    outputs = [\n        Output(name=\"video_out\", display_name=\"è§†é¢‘è·¯å¾„\", method=\"send\"),\n    ]\n\n    def send(self) -> Data:\n        path = Path(self.video_path)\n        if not path.exists():\n            raise FileNotFoundError(path)\n        self.status = f\"å·²åŠ è½½ {path.name}\"\n        return Data(data={\"video_path\": str(path)})"
              },
              "video_path": {
                "_input_type": "FileInput",
                "advanced": false,
                "display_name": "è§†é¢‘æ–‡ä»¶",
                "dynamic": false,
                "fileTypes": [
                  "mp4",
                  "mov",
                  "mkv"
                ],
                "file_path": "56aad5e5-4b5e-49b3-946e-71b04540eff1/6d88afc6-c982-4f00-bf9d-328b1eb4def9.mp4",
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "video_path",
                "placeholder": "",
                "required": true,
                "show": true,
                "temp_file": false,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "VideoInput"
        },
        "dragging": false,
        "id": "VideoInput-opMrl",
        "measured": {
          "height": 236,
          "width": 320
        },
        "position": {
          "x": -132.62173647890376,
          "y": 23.13851897026084
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "AudioExtractor-OocpO",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "ç”¨ FFmpeg åˆ†ç¦»éŸ³è½¨",
            "display_name": "2ï¸âƒ£ éŸ³é¢‘æå–",
            "documentation": "",
            "edited": true,
            "field_order": [
              "video_in",
              "duration"
            ],
            "frozen": false,
            "icon": "music",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "éŸ³é¢‘è·¯å¾„",
                "hidden": false,
                "method": "extract",
                "name": "audio_out",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# media_pipeline/2_audio_extractor.py\r\nfrom pathlib import Path\r\n\r\nfrom langflow.custom import Component\r\n# å¯¼å…¥ FloatInput ä»¥æ¥æ”¶æµ®ç‚¹æ•°ä½œä¸ºè¾“å…¥\r\nfrom langflow.io import DataInput, FloatInput, Output\r\nfrom langflow.schema import Data\r\n\r\nfrom .utils import run_ffmpeg\r\n\r\n\r\nclass AudioExtractor(Component):\r\n    display_name = \"2ï¸âƒ£ éŸ³é¢‘æå–\"\r\n    description = \"ç”¨ FFmpeg åˆ†ç¦»éŸ³è½¨\"\r\n    icon = \"music\"\r\n    name = \"AudioExtractor\"\r\n\r\n    inputs = [\r\n        DataInput(name=\"video_in\", display_name=\"è§†é¢‘è·¯å¾„\"),\r\n        # æ–°å¢ä¸€ä¸ªæµ®ç‚¹æ•°è¾“å…¥é¡¹æ¥æ§åˆ¶éŸ³é¢‘æˆªå–æ—¶é•¿\r\n        StrInput(\r\n            name=\"duration\",\r\n            display_name=\"æˆªå–æ—¶é•¿ (ç§’)\",\r\n            info=\"è®¾ç½®æå–éŸ³é¢‘çš„æ—¶é•¿ï¼Œå•ä½ä¸ºç§’ã€‚å¦‚æœè®¾ç½®ä¸º0æˆ–è´Ÿæ•°ï¼Œåˆ™æå–å®Œæ•´éŸ³é¢‘ã€‚\",\r\n            value=10,  # é»˜è®¤å€¼ä¸º0ï¼Œè¡¨ç¤ºæå–å®Œæ•´éŸ³é¢‘\r\n        ),\r\n    ]\r\n    outputs = [Output(name=\"audio_out\", display_name=\"éŸ³é¢‘è·¯å¾„\", method=\"extract\")]\r\n\r\n    def extract(self) -> Data:\r\n        \"\"\"\r\n        ä»è§†é¢‘æ–‡ä»¶ä¸­æå–éŸ³è½¨ï¼Œå¹¶æ ¹æ®ç”¨æˆ·è®¾å®šçš„æ—¶é•¿è¿›è¡Œæˆªå–ã€‚\r\n        \"\"\"\r\n        video = Path(self.video_in.data[\"video_path\"])\r\n        audio = video.with_suffix(\".wav\")\r\n\r\n        # åŸºç¡€ FFmpeg å‘½ä»¤\r\n        cmd = [\r\n            \"ffmpeg\",\r\n            \"-y\",          # æ— éœ€ç¡®è®¤ï¼Œç›´æ¥è¦†ç›–è¾“å‡ºæ–‡ä»¶\r\n            \"-i\", str(video), # è¾“å…¥æ–‡ä»¶\r\n            \"-vn\",         # å»é™¤è§†é¢‘æµ\r\n            \"-ac\", \"1\",      # è®¾ç½®éŸ³é¢‘é€šé“ä¸ºå•å£°é“\r\n            \"-ar\", \"16000\",  # è®¾ç½®é‡‡æ ·ç‡ä¸º 16000 Hz\r\n        ]\r\n\r\n        cmd.extend([\"-t\", str(self.duration)])\r\n\r\n        # å°†è¾“å‡ºæ–‡ä»¶è·¯å¾„æ·»åŠ åˆ°å‘½ä»¤æœ«å°¾\r\n        cmd.append(str(audio))\r\n\r\n        # æ‰§è¡Œ FFmpeg å‘½ä»¤\r\n        run_ffmpeg(cmd)\r\n\r\n        self.status = f\"éŸ³é¢‘ â†’ {audio.name}\"\r\n        return Data(data={\"audio_path\": str(audio)})"
              },
              "duration": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "æˆªå–æ—¶é•¿ (ç§’)",
                "dynamic": false,
                "info": "è®¾ç½®æå–éŸ³é¢‘çš„æ—¶é•¿ï¼Œå•ä½ä¸ºç§’ã€‚å¦‚æœè®¾ç½®ä¸º0æˆ–è´Ÿæ•°ï¼Œåˆ™æå–å®Œæ•´éŸ³é¢‘ã€‚",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "duration",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "180"
              },
              "video_in": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "è§†é¢‘è·¯å¾„",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "video_in",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AudioExtractor"
        },
        "dragging": false,
        "id": "AudioExtractor-OocpO",
        "measured": {
          "height": 274,
          "width": 320
        },
        "position": {
          "x": 239.8786048413947,
          "y": 15.734050601600686
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "VideoComposer-QNxnb",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "ç”¨æ–°éŸ³è½¨æ›¿æ¢åŸè§†é¢‘",
            "display_name": "ğŸ”Ÿ è§†é¢‘åˆæˆ",
            "documentation": "",
            "edited": false,
            "field_order": [
              "video_in",
              "audio_in"
            ],
            "frozen": false,
            "icon": "film",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "é…éŸ³è§†é¢‘",
                "hidden": false,
                "method": "compose",
                "name": "video_out",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "audio_in": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "åˆå¹¶éŸ³é¢‘",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "audio_in",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# media_pipeline/10_video_composer.py\nfrom pathlib import Path\n\nfrom langflow.custom import Component\nfrom langflow.io import DataInput, Output\nfrom langflow.schema import Data\n\nfrom .utils import run_ffmpeg\n\n\nclass VideoComposer(Component):\n    display_name = \"ğŸ”Ÿ è§†é¢‘åˆæˆ\"\n    description = \"ç”¨æ–°éŸ³è½¨æ›¿æ¢åŸè§†é¢‘\"\n    icon = \"film\"\n    name = \"VideoComposer\"\n\n    inputs = [\n        DataInput(name=\"video_in\", display_name=\"è§†é¢‘è·¯å¾„\"),\n        DataInput(name=\"audio_in\", display_name=\"åˆå¹¶éŸ³é¢‘\"),\n    ]\n    outputs = [Output(name=\"video_out\", display_name=\"é…éŸ³è§†é¢‘\", method=\"compose\")]\n\n    def compose(self) -> Data:\n        video = Path(self.video_in.data[\"video_path\"])\n        audio = Path(self.audio_in.data[\"merged_audio\"])\n        out_video = video.with_name(f\"{video.stem}_dubbed.mp4\")\n\n        run_ffmpeg(\n            [\n                \"ffmpeg\",\n                \"-y\",\n                \"-i\",\n                str(video),\n                \"-i\",\n                str(audio),\n                \"-c:v\",\n                \"copy\",\n                \"-c:a\",\n                \"aac\",\n                \"-map\",\n                \"0:v:0\",\n                \"-map\",\n                \"1:a:0\",\n                \"-shortest\",\n                str(out_video),\n            ]\n        )\n        self.status = f\"ç”Ÿæˆ {out_video.name}\"\n        return Data(data={\"dubbed_video\": str(out_video)})"
              },
              "video_in": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "è§†é¢‘è·¯å¾„",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "video_in",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "VideoComposer"
        },
        "dragging": false,
        "id": "VideoComposer-QNxnb",
        "measured": {
          "height": 236,
          "width": 320
        },
        "position": {
          "x": 254.72402798432506,
          "y": 628.827916047025
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SpeakerDiarization-z5MtQ",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "HuggingFace pyannote",
            "display_name": "3ï¸âƒ£ è¯´è¯äººåˆ†ç¦»",
            "documentation": "",
            "edited": true,
            "field_order": [
              "audio_in",
              "hf_token"
            ],
            "frozen": false,
            "icon": "users",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "è¯´è¯ç‰‡æ®µ",
                "hidden": false,
                "method": "diarize",
                "name": "segments_out",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "audio_in": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "éŸ³é¢‘è·¯å¾„",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "audio_in",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# media_pipeline/3_speaker_diarization.py\nfrom pathlib import Path\nfrom typing import List, Dict, Any\n\nfrom langflow.custom import Component\nfrom langflow.io import DataInput, StrInput, Output\nfrom langflow.schema import Data\n\n\nclass SpeakerDiarization(Component):\n    display_name = \"3ï¸âƒ£ è¯´è¯äººåˆ†ç¦»\"\n    description = \"HuggingFace pyannote\"\n    icon = \"users\"\n    name = \"SpeakerDiarization\"\n\n    inputs = [\n        DataInput(name=\"audio_in\", display_name=\"éŸ³é¢‘è·¯å¾„\"),\n        StrInput(\n            name=\"hf_token\",\n            display_name=\"HF Token(ç§æœ‰æ¨¡å‹ç”¨)\",\n            advanced=True,\n            value=\"\",\n        ),\n    ]\n    outputs = [Output(name=\"segments_out\", display_name=\"è¯´è¯ç‰‡æ®µ\", method=\"diarize\")]\n\n    def diarize(self) -> Data:\n        from pyannote.audio import Pipeline\n\n        audio_path = Path(self.audio_in.data[\"audio_path\"])\n        pipeline = Pipeline.from_pretrained(\n            \"pyannote/speaker-diarization-3.1\",\n            use_auth_token=self.hf_token or None,\n        ).to(torch.device(\"cuda\"))\n        diar = pipeline(str(audio_path))\n\n        segs: List[Dict[str, Any]] = []\n        for turn, _, speaker in diar.itertracks(yield_label=True):\n            segs.append(\n                dict(\n                    speaker=speaker,\n                    start=round(turn.start, 3),\n                    end=round(turn.end, 3),\n                )\n            )\n        self.status = f\"ç‰‡æ®µæ•°: {len(segs)}\"\n        return Data(data={\"segments\": segs, \"audio_path\": str(audio_path)})"
              },
              "hf_token": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "HF Token(ç§æœ‰æ¨¡å‹ç”¨)",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "hf_token",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SpeakerDiarization"
        },
        "dragging": false,
        "id": "SpeakerDiarization-z5MtQ",
        "measured": {
          "height": 192,
          "width": 320
        },
        "position": {
          "x": 630.047337299925,
          "y": 17.651842511504853
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SegmentASR-YElxR",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Whisper (HF pipeline)",
            "display_name": "4ï¸âƒ£ è¯­éŸ³è¯†åˆ«",
            "documentation": "",
            "edited": true,
            "field_order": [
              "seg_in"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "è½¬å†™ç»“æœ",
                "hidden": false,
                "method": "transcribe",
                "name": "asr_out",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from pathlib import Path\r\nfrom typing import List, Dict, Any\r\n\r\nimport torch\r\nfrom langflow.custom import Component\r\nfrom langflow.io import DataInput, Output\r\nfrom langflow.schema import Data\r\n\r\n# Import any utility functions like run_ffmpeg if needed\r\nfrom .utils import run_ffmpeg\r\n\r\n\r\nclass SegmentASR(Component):\r\n    display_name = \"4ï¸âƒ£ è¯­éŸ³è¯†åˆ«\"\r\n    description = \"Whisper (HF pipeline)\"\r\n    icon = \"type\"\r\n    name = \"SegmentASR\"\r\n\r\n    # Define inputs and outputs for the component\r\n    inputs = [DataInput(name=\"seg_in\", display_name=\"è¯´è¯ç‰‡æ®µ\")]\r\n    outputs = [Output(name=\"asr_out\", display_name=\"è½¬å†™ç»“æœ\", method=\"transcribe\")]\r\n\r\n    # Main transcription method\r\n    def transcribe(self) -> Data:\r\n        import whisper\r\n    \r\n        # Load the Whisper model\r\n        model = whisper.load_model(\"small\")\r\n    \r\n        segs: List[Dict[str, Any]] = self.seg_in.data[\"segments\"]\r\n        audio_path = Path(self.seg_in.data[\"audio_path\"])\r\n    \r\n        results = []\r\n        for seg in segs:\r\n            # Extract individual audio segments using FFmpeg\r\n            wav_seg = audio_path.with_name(\r\n                f\"{audio_path.stem}_{seg['start']:.2f}_{seg['end']:.2f}.wav\"\r\n            )\r\n            run_ffmpeg(\r\n                [\r\n                    \"ffmpeg\",\r\n                    \"-y\",\r\n                    \"-i\",\r\n                    str(audio_path),\r\n                    \"-ss\",\r\n                    str(seg[\"start\"]),\r\n                    \"-to\",\r\n                    str(seg[\"end\"]),\r\n                    str(wav_seg),\r\n                ]\r\n            )\r\n    \r\n            # Use Whisper for transcription and language detection\r\n            result = model.transcribe(str(wav_seg))\r\n            text = result[\"text\"].strip()\r\n            language = result.get(\"language\", \"unknown\")  # Retrieve detected language\r\n    \r\n            # Append result for this segment\r\n            results.append(\r\n                {**seg, \"text\": text, \"language\": language, \"wav\": str(wav_seg)}\r\n            )\r\n    \r\n        # Update the component's status and return results\r\n        self.status = f\"ASR å®Œæˆ {len(results)} æ®µ\"\r\n        return Data(data={\"results\": results})"
              },
              "seg_in": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "è¯´è¯ç‰‡æ®µ",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "seg_in",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SegmentASR"
        },
        "dragging": false,
        "id": "SegmentASR-YElxR",
        "measured": {
          "height": 192,
          "width": 320
        },
        "position": {
          "x": 1002.8280383535255,
          "y": 32.0634603817152
        },
        "selected": true,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "SpeakerAttribute-oyrcV",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "æƒ…æ„Ÿ + æ€§åˆ« + è¯­é€Ÿ",
            "display_name": "5ï¸âƒ£ å±æ€§åˆ†æ",
            "documentation": "",
            "edited": false,
            "field_order": [
              "asr_in"
            ],
            "frozen": false,
            "icon": "activity",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "å±æ€§ç»“æœ",
                "hidden": false,
                "method": "analyze",
                "name": "attr_out",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "asr_in": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "è½¬å†™ç»“æœ",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "asr_in",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# media_pipeline/5_speaker_attribute.py\nimport torch\nfrom langflow.custom import Component\nfrom langflow.io import DataInput, Output\nfrom langflow.schema import Data\n\n\nclass SpeakerAttribute(Component):\n    display_name = \"5ï¸âƒ£ å±æ€§åˆ†æ\"\n    description = \"æƒ…æ„Ÿ + æ€§åˆ« + è¯­é€Ÿ\"\n    icon = \"activity\"\n    name = \"SpeakerAttribute\"\n\n    inputs = [DataInput(name=\"asr_in\", display_name=\"è½¬å†™ç»“æœ\")]\n    outputs = [Output(name=\"attr_out\", display_name=\"å±æ€§ç»“æœ\", method=\"analyze\")]\n\n    def analyze(self) -> Data:\n        from transformers import pipeline\n\n        emo_pipe = pipeline(\n            \"text-classification\",\n            model=\"cardiffnlp/twitter-roberta-base-emotion\",\n            top_k=None,\n        )\n\n        items = self.asr_in.data[\"results\"]\n        for it in items:\n            it[\"emotion\"] = emo_pipe(it[\"text\"])[0][0][\"label\"]\n            dur = it[\"end\"] - it[\"start\"]\n            it[\"speed_wps\"] = round(len(it[\"text\"].split()) / dur, 2)\n\n        self.status = \"å±æ€§åˆ†æå®Œæˆ\"\n        return Data(data={\"items\": items})"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "SpeakerAttribute"
        },
        "dragging": false,
        "id": "SpeakerAttribute-oyrcV",
        "measured": {
          "height": 192,
          "width": 320
        },
        "position": {
          "x": -127.23654677629533,
          "y": 362.0618003411949
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DialogueTable-anbT7",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "ç”Ÿæˆç»“æ„åŒ– DataFrame",
            "display_name": "6ï¸âƒ£ å¯¹ç™½è¡¨",
            "documentation": "",
            "edited": false,
            "field_order": [
              "attr_in"
            ],
            "frozen": false,
            "icon": "table",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [
              "DataFrame"
            ],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "å¯¹ç™½è¡¨",
                "hidden": false,
                "method": "build",
                "name": "df_out",
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "attr_in": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "å±æ€§ç»“æœ",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "attr_in",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# media_pipeline/6_dialogue_table.py\nimport pandas as pd\nfrom langflow.custom import Component\nfrom langflow.io import DataInput, Output\nfrom langflow.schema import DataFrame\n\n\nclass DialogueTable(Component):\n    display_name = \"6ï¸âƒ£ å¯¹ç™½è¡¨\"\n    description = \"ç”Ÿæˆç»“æ„åŒ– DataFrame\"\n    icon = \"table\"\n    name = \"DialogueTable\"\n\n    inputs = [DataInput(name=\"attr_in\", display_name=\"å±æ€§ç»“æœ\")]\n    outputs = [Output(name=\"df_out\", display_name=\"å¯¹ç™½è¡¨\", method=\"build\")]\n\n    def build(self) -> DataFrame:\n        df = pd.DataFrame(self.attr_in.data[\"items\"])\n        self.status = f\"è¡Œæ•°: {len(df)}\"\n        return DataFrame(df)"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DialogueTable"
        },
        "dragging": false,
        "id": "DialogueTable-anbT7",
        "measured": {
          "height": 192,
          "width": 320
        },
        "position": {
          "x": 261.52502328467466,
          "y": 359.255751768256
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PoeTranslator-K0YVQ",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "ä½¿ç”¨ Poe API è¿›è¡Œæ–‡æœ¬ç¿»è¯‘å’Œå¯¹è¯æ¶¦è‰²",
            "display_name": "7ï¸âƒ£ Poe API ç¿»è¯‘ä¸æ¶¦è‰²",
            "documentation": "",
            "edited": true,
            "field_order": [
              "df_in",
              "api_key",
              "bot_name",
              "tgt_lang",
              "enable_polishing"
            ],
            "frozen": false,
            "icon": "globe-2",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "ç¿»è¯‘åè¡¨",
                "hidden": false,
                "method": "translate",
                "name": "df_out",
                "options": null,
                "required_inputs": null,
                "selected": "DataFrame",
                "tool_mode": true,
                "types": [
                  "DataFrame"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Poe API Key",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "api_key",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "bot_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Poe Bot åç§°",
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "name": "bot_name",
                "options": [
                  "Claude-3.5-Sonnet",
                  "GPT-4o",
                  "Assistant",
                  "Claude-3-Opus"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "GPT-4o"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import pandas as pd\r\nfrom langflow.custom import Component\r\nfrom langflow.io import (\r\n    DataFrameInput,\r\n    DropdownInput,\r\n    Output,\r\n    StrInput,\r\n    BoolInput,\r\n)\r\nfrom langflow.schema import DataFrame\r\n\r\nclass PoeTranslator(Component):\r\n    display_name = \"7ï¸âƒ£ Poe API ç¿»è¯‘ä¸æ¶¦è‰²\"\r\n    description = \"ä½¿ç”¨ Poe API è¿›è¡Œæ–‡æœ¬ç¿»è¯‘å’Œå¯¹è¯æ¶¦è‰²\"\r\n    icon = \"globe-2\"\r\n    name = \"PoeTranslator\"\r\n\r\n    inputs = [\r\n        DataFrameInput(name=\"df_in\", display_name=\"å¯¹ç™½è¡¨\", required=True),\r\n        StrInput(\r\n            name=\"api_key\",\r\n            display_name=\"Poe API Key\",\r\n            required=True,\r\n            value = \"\"\r\n        ),\r\n        DropdownInput(\r\n            name=\"bot_name\",\r\n            display_name=\"Poe Bot åç§°\",\r\n            options=[\"Claude-3.5-Sonnet\", \"GPT-4o\", \"Assistant\", \"Claude-3-Opus\"],\r\n            value=\"Claude-3.5-Sonnet\",\r\n        ),\r\n        DropdownInput(\r\n            name=\"tgt_lang\",\r\n            display_name=\"ç›®æ ‡è¯­è¨€\",\r\n            options=[\"zh\", \"de\", \"fr\", \"es\", \"ja\", \"ko\", \"ru\"],\r\n            value=\"zh\",\r\n        ),\r\n        BoolInput(\r\n            name=\"enable_polishing\",\r\n            display_name=\"å¯ç”¨æ¶¦è‰²\",\r\n            value=True\r\n        ),\r\n    ]\r\n    outputs = [Output(name=\"df_out\", display_name=\"ç¿»è¯‘åè¡¨\", method=\"translate\")]\r\n\r\n    def translate(self) -> DataFrame:\r\n        \"\"\"\r\n        Connects to the Poe API to perform translation and optional dialogue polishing.\r\n        \"\"\"\r\n        import fastapi_poe as fp\r\n        df: pd.DataFrame = self.df_in.copy()\r\n        src_texts = df[\"text\"].tolist()\r\n        api_key = self.api_key\r\n        bot_name = self.bot_name\r\n        enable_polishing = self.enable_polishing\r\n\r\n        if not api_key:\r\n            raise ValueError(\"Poe API Key is required.\")\r\n\r\n        # A mapping from language code to full language name for clearer prompts.\r\n        lang_map = {\r\n            \"zh\": \"Chinese (Simplified)\",\r\n            \"de\": \"German\",\r\n            \"fr\": \"French\",\r\n            \"es\": \"Spanish\",\r\n            \"ja\": \"Japanese\",\r\n            \"ko\": \"Korean\",\r\n            \"ru\": \"Russian\",\r\n        }\r\n        target_language_name = lang_map.get(self.tgt_lang, self.tgt_lang)\r\n\r\n        translated_texts = []\r\n        total_rows = len(src_texts)\r\n\r\n        for i, text in enumerate(src_texts):\r\n            self.status = f\"æ­£åœ¨å¤„ç†: {i + 1}/{total_rows}\"\r\n            try:\r\n                # Construct the prompt based on user's choice.\r\n                if enable_polishing:\r\n                    prompt = (\r\n                        f\"You are an expert translator and editor. First, remove the sentences that are nothing to do with the context\"\r\n                        f\"translate the following English dialogue into {target_language_name}. \"\r\n                        f\"Then, polish the translated text to make it sound perfectly natural, fluent, and authentic for a native speaker. \"\r\n                        f\"Provide ONLY the final, polished translation, without any explanations or original text.\\n\\n\"\r\n                        f'Original English Text: \"{text}\"'\r\n                    )\r\n                else:\r\n                    prompt = (\r\n                        f\"Translate the following English text to {target_language_name}. \"\r\n                        f\"Provide only the translation, with no extra text or explanations.\\n\\n\"\r\n                        f'\"{text}\"'\r\n                    )\r\n\r\n                # Prepare the message for the Poe API\r\n                message = fp.ProtocolMessage(role=\"user\", content=prompt)\r\n\r\n                # Call the synchronous API endpoint\r\n                response_text = \"\"\r\n                for partial_response in fp.get_bot_response_sync(\r\n                    messages=[message], bot_name=bot_name, api_key=api_key\r\n                ):\r\n                    response_text += partial_response.text\r\n\r\n                translated_texts.append(response_text)\r\n\r\n            except Exception as e:\r\n                # Handle API errors or other exceptions\r\n                error_message = f\"åœ¨å¤„ç†ç¬¬ {i + 1} è¡Œæ—¶å‡ºé”™: {e}\"\r\n                self.status = error_message\r\n                # Append an error message to the results to maintain row alignment\r\n                translated_texts.append(f\"ERROR: {e}\")\r\n                # Optionally, you might want to stop the process on the first error\r\n                # raise RuntimeError(error_message) from e\r\n\r\n        df[\"translated\"] = translated_texts\r\n        self.status = f\"ç¿»è¯‘å®Œæˆ! å…±å¤„ç† {total_rows} è¡Œã€‚\\n{df}\"\r\n        return DataFrame(df)"
              },
              "df_in": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "å¯¹ç™½è¡¨",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df_in",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "enable_polishing": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "å¯ç”¨æ¶¦è‰²",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "enable_polishing",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "tgt_lang": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "ç›®æ ‡è¯­è¨€",
                "dynamic": false,
                "info": "",
                "name": "tgt_lang",
                "options": [
                  "zh",
                  "de",
                  "fr",
                  "es",
                  "ja",
                  "ko",
                  "ru"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "zh"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PoeTranslator"
        },
        "dragging": false,
        "id": "PoeTranslator-K0YVQ",
        "measured": {
          "height": 399,
          "width": 320
        },
        "position": {
          "x": 631.9740438393949,
          "y": 291.1104816293506
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ZeroShotTTS-XOsVg",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Coqui XTTS v2",
            "display_name": "8ï¸âƒ£ Zero-Shot TTS",
            "documentation": "",
            "edited": true,
            "field_order": [
              "df_in"
            ],
            "frozen": false,
            "icon": "mic",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "TTS ç‰‡æ®µ",
                "hidden": false,
                "method": "synthesize",
                "name": "tts_out",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# media_pipeline/8_zero_shot_tts.py\r\nfrom pathlib import Path\r\nfrom typing import List, Dict, Any\r\n\r\nimport pandas as pd\r\nfrom langflow.custom import Component\r\nfrom langflow.io import DataFrameInput, Output\r\nfrom langflow.schema import Data\r\nfrom textwrap import wrap  # For splitting text into smaller chunks\r\nimport soundfile as sf\r\n\r\n\r\nMAX_TOKENS = 300  # XTTS model token limit\r\n\r\n\r\nclass ZeroShotTTS(Component):\r\n    display_name = \"8ï¸âƒ£ Zero-Shot TTS\"\r\n    description = \"Coqui XTTS v2\"\r\n    icon = \"mic\"\r\n    name = \"ZeroShotTTS\"\r\n\r\n    inputs = [DataFrameInput(name=\"df_in\", display_name=\"ç¿»è¯‘åè¡¨\")]\r\n    outputs = [Output(name=\"tts_out\", display_name=\"TTS ç‰‡æ®µ\", method=\"synthesize\")]\r\n\r\n    def synthesize(self) -> Data:\r\n        from TTS.api import TTS  # Import TTS library\r\n\r\n        tts = TTS(model_name=\"tts_models/multilingual/multi-dataset/xtts_v2\", progress_bar=False, gpu=True)\r\n\r\n        df: pd.DataFrame = self.df_in\r\n\r\n        # Validate input DataFrame\r\n        if df.empty or not all(col in df.columns for col in [\"wav\", \"translated\", \"start\", \"end\"]):\r\n            raise ValueError(\"Input DataFrame is empty or missing required columns: 'wav', 'translated', 'start', 'end'\")\r\n\r\n        df = df.dropna(subset=[\"wav\", \"translated\", \"start\", \"end\"])\r\n\r\n        pieces: List[Dict[str, Any]] = []\r\n        for _, row in df.iterrows():\r\n            ref = Path(row[\"wav\"])\r\n            if not ref.is_file():\r\n                raise FileNotFoundError(f\"Reference audio file not found: {ref}\")\r\n\r\n            # Validate audio file\r\n            with sf.SoundFile(ref) as f:\r\n                duration = len(f) / f.samplerate\r\n                if duration < 1.0:\r\n                    continue\r\n\r\n            out_wav = ref.with_suffix(\".tts.wav\")\r\n\r\n            try:\r\n                # Split text into chunks of 400 tokens or fewer\r\n                translated_text = row[\"translated\"]\r\n                text_chunks = wrap(translated_text, MAX_TOKENS)\r\n\r\n                chunk_wavs = []\r\n\r\n                for i, chunk in enumerate(text_chunks):\r\n                    chunk_out_wav = ref.with_name(f\"{ref.stem}_chunk_{i}.tts.wav\")\r\n                    tts.tts_to_file(\r\n                        chunk,\r\n                        file_path=str(chunk_out_wav),\r\n                        speaker_wav=str(ref),\r\n                        language=\"zh\",\r\n                    )\r\n                    chunk_wavs.append(str(chunk_out_wav))\r\n\r\n                # Combine all chunk WAVs into a single entry\r\n                pieces.append({\r\n                    \"start\": row[\"start\"],\r\n                    \"end\": row[\"end\"],\r\n                    \"wav\": chunk_wavs,\r\n                })\r\n\r\n            except RuntimeError as e:\r\n                print(f\"Speaker conditioning failed for {ref}, falling back to default speaker.\")\r\n                tts.tts_to_file(\r\n                    row[\"translated\"],\r\n                    file_path=str(out_wav),\r\n                    language=\"zh\",\r\n                )\r\n                pieces.append(dict(start=row[\"start\"], end=row[\"end\"], wav=str(out_wav)))\r\n\r\n            except Exception as e:\r\n                raise RuntimeError(f\"TTS generation failed for row: {row}\") from e\r\n\r\n        self.status = f\"TTS generated {len(pieces)} segments\"\r\n        return Data(data={\"tts_segments\": pieces})"
              },
              "df_in": {
                "_input_type": "DataFrameInput",
                "advanced": false,
                "display_name": "ç¿»è¯‘åè¡¨",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "DataFrame"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "df_in",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ZeroShotTTS"
        },
        "dragging": false,
        "id": "ZeroShotTTS-XOsVg",
        "measured": {
          "height": 192,
          "width": 320
        },
        "position": {
          "x": 1004.5529592868082,
          "y": 286.3548890114634
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "AudioMerger-SjPk8",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "æŒ‰æ—¶é—´æˆ³å åŠ éŸ³è½¨",
            "display_name": "9ï¸âƒ£ éŸ³é¢‘åˆå¹¶",
            "documentation": "",
            "edited": true,
            "field_order": [
              "tts_in"
            ],
            "frozen": false,
            "icon": "layers",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "åˆå¹¶éŸ³é¢‘",
                "hidden": false,
                "method": "merge",
                "name": "audio_out",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# media_pipeline/9_audio_merger.py\r\nfrom pathlib import Path\r\n\r\nfrom pydub import AudioSegment\r\nfrom langflow.custom import Component\r\nfrom langflow.io import DataInput, Output\r\nfrom langflow.schema import Data\r\n\r\n\r\nclass AudioMerger(Component):\r\n    display_name = \"9ï¸âƒ£ éŸ³é¢‘åˆå¹¶\"\r\n    description = \"æŒ‰æ—¶é—´æˆ³å åŠ éŸ³è½¨\"\r\n    icon = \"layers\"\r\n    name = \"AudioMerger\"\r\n\r\n    inputs = [DataInput(name=\"tts_in\", display_name=\"TTS ç‰‡æ®µ\")]\r\n    outputs = [Output(name=\"audio_out\", display_name=\"åˆå¹¶éŸ³é¢‘\", method=\"merge\")]\r\n\r\n    def merge(self) -> Data:\r\n        segs = sorted(self.tts_in.data[\"tts_segments\"], key=lambda x: x[\"start\"])\r\n        end_ms = int(max(s[\"end\"] for s in segs) * 1000) + 500\r\n        merged = AudioSegment.silent(duration=end_ms)\r\n\r\n        for s in segs:\r\n            part = AudioSegment.from_file(s[\"wav\"])\r\n            merged = merged.overlay(part, position=int(s[\"start\"] * 1000))\r\n\r\n        out = Path(segs[0][\"wav\"]).with_name(\"merged_tts.wav\")\r\n        merged.export(out, format=\"wav\")\r\n        self.status = f\"è¾“å‡º {out.name}\"\r\n        return Data(data={\"merged_audio\": str(out)})"
              },
              "tts_in": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "TTS ç‰‡æ®µ",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "tts_in",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "AudioMerger"
        },
        "dragging": false,
        "id": "AudioMerger-SjPk8",
        "measured": {
          "height": 192,
          "width": 320
        },
        "position": {
          "x": -124.20511364327453,
          "y": 634.8907823130666
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatOutput-1nIGb",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.4.3",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ChatOutput"
        },
        "dragging": false,
        "id": "ChatOutput-1nIGb",
        "measured": {
          "height": 192,
          "width": 320
        },
        "position": {
          "x": 1003.6458717543452,
          "y": 643.0055173879921
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 128.82176498569015,
      "y": 16.546217183596298,
      "zoom": 0.6244961586584619
    }
  },
  "description": "Where Language Meets Logic.",
  "endpoint_name": null,
  "id": "3fd05698-b83c-4938-a111-d39fa4484ff3",
  "is_component": false,
  "last_tested_version": "1.4.3",
  "name": "cvv",
  "tags": []
}